{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5f30e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
    "from dataloader import read_mathqapython, MathQAPython "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5397f5e9",
   "metadata": {},
   "source": [
    "# MathQA dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "942a5f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MathQAPython(torch.utils.data.Dataset): \n",
    "    def __init__(self, instance_list, tokenizer, text_len, code_len): \n",
    "        self.data = instance_list \n",
    "        self.tokenizer = tokenizer \n",
    "        self.text_len = text_len\n",
    "        self.code_len = code_len\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "        idx = idx + 2\n",
    "        instance = self.data[idx]\n",
    "        text = instance['text']\n",
    "        code = instance['code']\n",
    "        answer = instance['answer']\n",
    "\n",
    "        text_encode = self.tokenizer(text, max_length=self.text_len, \n",
    "                                     padding='max_length', return_tensors='pt')\n",
    "        code_encode = self.tokenizer(code, max_length=self.code_len, \n",
    "                                     padding='max_length', return_tensors='pt')\n",
    "        text_ids = text_encode['input_ids'].squeeze()\n",
    "        code_ids = code_encode['input_ids'].squeeze()\n",
    "\n",
    "        return text_ids.to(dtype=torch.long), code_ids.to(dtype=torch.long), answer\n",
    "\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.data) - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458c07aa",
   "metadata": {},
   "source": [
    "# Few-shot evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c297c994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at some data\n",
    "data = read_mathqapython('data/mathqapython_dev.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cccd785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '# mr . kramer , the losing candidate in a two - candidate election , received 942,568 votes , which was exactly 25 percent of all votes cast . approximately what percent of the remaining votes would he need to have received in order to have won at least 50 percent of all the votes cast ? n0 = 942568.0 n1 = 25.0 n2 = 50.0',\n",
       " 'code': 'n0 = 942568.0\\nn1 = 25.0\\nn2 = 50.0\\nt0 = n2 / 100.0\\nt1 = n1 / 100.0\\nt2 = t0 - t1\\nt3 = 1.0 - t1\\nt4 = t2 / t3\\nanswer = t4 * 100.0',\n",
       " 'dsl_code': 'divide(n2,const_100)|divide(n1,const_100)|subtract(#0,#1)|subtract(const_1,#1)|divide(#2,#3)|multiply(#4,const_100)|',\n",
       " 'reasoning': 'lets assume that candidate got 25 % votes and total votes is 100 . candidate won = 25 remaining = 75 to get 50 % , candidate requires 25 votes from 100 which is 25 % and 25 votes from 75 . 25 / 75 = 33.33 % which is approx 33 % . hence the answer is e',\n",
       " 'answer': 33.33333333333333,\n",
       " 'task_id': 35}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8ce2180",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d76e8e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1707\n",
      "# a multiple choice test consists of 4 questions , and each question has 5 answer choices . in how many r ways can the test be completed if every question is unanswered ? n0 = 4.0 n1 = 5.0\n",
      "n0 = 4.0\n",
      "n1 = 5.0\n",
      "\n",
      "answer = n1**min(n0, 5)\n",
      "\n",
      "# the hcf and lcm of two numbers m and n are respectively 6 and 210 . if m + n = 72 , then 1 / m + 1 / n is equal to n0 = 6.0 n1 = 210.0 n2 = 72.0 n3 = 1.0 n4 = 1.0\n",
      "n0 = 6.0\n",
      "n1 = 210.0\n",
      "n2 = 72.0\n",
      "n3 = 1.0\n",
      "n4 = 1.0\n",
      "t0 = n0 * n1\n",
      "answer = n2 / t0\n",
      "\n",
      "# in a kilometer race , a beats b by 48 meters or 12 seconds . what time does a take to complete the race ? n0 = 48.0 n1 = 12.0\n",
      "n0 = 48.0\n",
      "n1 = 12.0\n",
      "t0 = n0 / n1\n",
      "t1 = 1.0 * 1000.0\n",
      "t2 = t1 / t0\n",
      "answer = t2 - n1\n",
      "\n",
      "# in a school of 650 boys , 44 % of muslims , 28 % hindus , 10 % sikhs and the remaining of other communities . how many belonged to the other communities ? n0 = 650.0 n1 = 44.0 n2 = 28.0 n3 = 10.0\n",
      "n0 = 650.0\n",
      "n1 = 44.0\n",
      "n2 = 28.0\n",
      "n3 = 10.0\n",
      "t0 = n1 + n2\n",
      "t1 = n3 + t0\n",
      "t2 = 100.0 - t1\n",
      "t3 = n0 * t2\n",
      "answer = t3 / 100.0\n",
      "\n",
      "# a can do a piece of work in 4 hours ; b and c together can do it in 3 hours , while a and c together can do it 2 hours . how long will b alone take to do it ? n0 = 4.0 n1 = 3.0 n2 = 2.0\n",
      "n0 = 4.0\n",
      "n1 = 3.0\n",
      "n2 = 2.0\n",
      "t0 = 1.0 / n1\n",
      "t1 = 1.0 / n2\n",
      "t2 = 1.0 / n0\n",
      "t3 = t1 - t2\n",
      "t4 = t0 - t3\n",
      "answer = 1.0 / t4\n",
      "\n",
      "# in a group of 160 people , 90 have an age of more 30 years , and the others have an age of less than 20 years . if a person is selected at random from this group , what is the probability the person ' s age is less than 20 ? n0 = 160.0 n1 = 90.0 n2 = 30.0 n3 = 20.0 n4 = 20.0\n",
      "n0 = 160.0\n",
      "n1 = 90.0\n",
      "n2 = 30.0\n",
      "n3 = 20.0\n",
      "n4 = 20.0\n",
      "t0 = n0 - n1\n",
      "answer = t0 / n0\n",
      "\n",
      "# an art gallery has only paintings and sculptures . currently , 1 / 3 of the pieces of art are displayed , and 1 / 6 of the pieces on display are sculptures . if 1 / 3 of the pieces not on display are paintings , and 800 sculptures are not on display , how many pieces of art does the gallery have ? n0 = 1.0 n1 = 3.0 n2 = 1.0 n3 = 6.0 n4 = 1.0 n5 = 3.0 n6 = 800.0\n",
      "n0 = 1.0\n",
      "n1 = 3.0\n",
      "n2 = 1.0\n",
      "n3 = 6.0\n",
      "n4 = 1.0\n",
      "n5 = 3.0\n",
      "n6 = 800.0\n",
      "t0 = n0 / n1\n",
      "t1 = n0 - t0\n",
      "t2 = n6 / t1\n",
      "answer = t2 / t1\n",
      "\n",
      "# at what rate of compound interest per annum will a sum of rs . 1200 become rs . 1348.32 in 2 years ? n0 = 1200.0 n1 = 1348.32 n2 = 2.0\n",
      "import math\n",
      "n0 = 1200.0\n",
      "n1 = 1348.32\n",
      "n2 = 2.0\n",
      "t0 = n0 / 100.0\n",
      "t1 = n1 * 100.0\n",
      "t2 = n0 * 100.0\n",
      "t3 = t1 / t0\n",
      "t4 = t2 / t0\n",
      "t5 = math.sqrt(max(0, t3))\n",
      "t6 = math.sqrt(max(0, t4))\n",
      "answer = t5 - t6\n",
      "\n",
      "# in the first 10 overs of a cricket game , the run rate was only 6.2 . what should be the run rate in the remaining 40 overs to reach the target of 282 runs ? n0 = 10.0 n1 = 6.2 n2 = 40.0 n3 = 282.0\n",
      "n0 = 10.0\n",
      "n1 = 6.2\n",
      "n2 = 40.0\n",
      "n3 = 282.0\n",
      "t0 = n0 * n1\n",
      "t1 = n3 - t0\n",
      "answer = t1 / n2\n",
      "\n",
      "# during a car trip , maria stopped to rest after she traveled 1 / 2 of the total distance to her destination . she stopped again after she traveled 1 / 4 of the distance remaining between her first stop and her destination , and then she drove the remaining 135 miles to her detination . what was the total distance , in miles from maria ' s starting point to her destination ? n0 = 1.0 n1 = 2.0 n2 = 1.0 n3 = 4.0 n4 = 135.0\n",
      "n0 = 1.0\n",
      "n1 = 2.0\n",
      "n2 = 1.0\n",
      "n3 = 4.0\n",
      "n4 = 135.0\n",
      "t0 = n0 / n1\n",
      "t1 = n0 / n3\n",
      "t2 = t0 * t1\n",
      "t3 = t0 + t2\n",
      "t4 = n0 - t3\n",
      "answer = n4 / t4\n",
      "\n",
      "# a and b go around a circular track of length 600 m on a cycle at speeds of 36 kmph and 54 kmph . after how much time will they meet for the first time at the starting point ? n0 = 600.0 n1 = 36.0 n2 = 54.0\n",
      "n0 = 600.0\n",
      "n1 = 36.0\n",
      "n2 = 54.0\n",
      "t0 = n2 * 0.2778\n",
      "t1 = n1 * 0.2778\n",
      "t2 = t0 - t1\n",
      "answer = n0 / t2\n",
      "\n",
      "# a certain car can travel 32 kilometers on a liter of fuel . if the fuel tank â€™ s contents decrease by 3.9 gallons over a period of 5.7 hours as the car moves at a constant speed , how fast is the car moving , in miles per hour ? ( 1 gallon = 3.8 liters ; 1 mile = 1.6 kilometers ) n0 = 32.0 n1 = 3.9 n2 = 5.7 n3 = 1.0 n4 = 3.8 n5 = 1.0 n6 = 1.6\n",
      "n0 = 32.0\n",
      "n1 = 3.9\n",
      "n2 = 5.7\n",
      "n3 = 1.0\n",
      "n4 = 3.8\n",
      "n5 = 1.0\n",
      "n6 = 1.6\n",
      "t0 = n0 * n4\n",
      "t1 = t0 / n6\n",
      "t2 = n1 * t1\n",
      "answer = t2 / n2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "few_shot_prompt = \"\\n\\n\".join([example['text'] + '\\n' + example['code'] for example in data[0:12] ]) + '\\n\\n'\n",
    "print(len(tokenizer(few_shot_prompt)['input_ids']))\n",
    "print(few_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d5a90b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = MathQAPython(data, tokenizer, 256, 256)\n",
    "\n",
    "loader = DataLoader(test_set, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63684c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc75139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "for batch in loader: \n",
    "    ids, gt, gt_answer = batch\n",
    "    encoded_few_shot_prompt = tokenizer(few_shot_prompt, return_tensors=\"pt\")['input_ids']\n",
    "    few_shot_ids = torch.cat([encoded_few_shot_prompt, ids], axis=1)\n",
    "    generated_ids = model.generate(\n",
    "        input_ids=few_shot_ids, \n",
    "        do_sample=True,\n",
    "        temperature=0.4, \n",
    "        max_length=2048\n",
    "        )\n",
    "    print(\"completion\" + \"#\"*20)\n",
    "    print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))\n",
    "    print(\"prompt\" + \"#\"*20)\n",
    "    print(tokenizer.decode(ids.squeeze(), skip_special_tokens=True))\n",
    "    print('#'*20 + 'ground truth code')\n",
    "    print(tokenizer.decode(gt.squeeze(), skip_special_tokens=True))\n",
    "\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6599cf4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'span'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26589/501420091.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_few_shot_prompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcompletion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprogram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompletion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'answer.*?\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompletion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'span'"
     ]
    }
   ],
   "source": [
    "start_idx = encoded_few_shot_prompt.size()[1]\n",
    "completion = tokenizer.decode(generated_ids[0, start_idx:])\n",
    "program = completion[:re.search('answer.*?\\n', completion).span()[1]]\n",
    "print(program)\n",
    "loc={}\n",
    "a = exec(code+last_line, globals(), loc)\n",
    "print(loc['answer'])\n",
    "print('ground truth answer: ', gt_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842fdce2",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcec5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e061ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_mathqapython('data/mathqapython_train.json')\n",
    "val_data = read_mathqapython('data/mathqapython_dev.json')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "train_set = MathQAPython(data[0:10], tokenizer, 1024, 1024)\n",
    "dev_set = MathQAPython(data[0:2], tokenizer, 1024, 1024)\n",
    "# loader = DataLoader(train_set, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d327288",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-125M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cbbb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir='./results', \n",
    "                                  num_train_epochs=2, \n",
    "                                  logging_steps=2, \n",
    "                                  save_steps=2, \n",
    "                                  per_device_train_batch_size=2, \n",
    "                                  per_device_eval_batch_size=2, \n",
    "                                  weight_decay=0.01, \n",
    "                                  label_names = ['code_ids'],\n",
    "                                  logging_dir='./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a6c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collator(data):\n",
    "    print(data)\n",
    "    return {'text_ids': torch.stack([f['text_ids'] for f in data]),\n",
    "            'code_ids': torch.stack([f['code_ids'] for f in data])\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d610e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainer(model=model, args=training_args, train_dataset=train_set, \n",
    "        eval_dataset=dev_set).train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
